{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r_UgZCtjiFa"
      },
      "source": [
        "## Feature Visualization of Deep Neural Networks\n",
        "- Prepared by Engin Deniz Erkan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6S6bkIw0C-c",
        "outputId": "8fb54913-c7a4-4d4b-dc45-92822e469ce2"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To save the images inside google drive, below code is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5WCFT2Yj6cp",
        "outputId": "6b2bdcc2-5772-4b7f-8967-4150d1b56576"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/MMI727_project_visualizations\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    print(f\"Directory does not exist: {output_dir}\")\n",
        "    sys.exit(f\"Exiting program: Directory does not exist: {output_dir}\")\n",
        "else:\n",
        "    print(f\"Directory exists: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZtMMp-taEDvi",
        "outputId": "ec945e60-93b6-43e7-89e4-c4feb2f13367"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import PIL\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "############################################################################################################\n",
        "##                       Utility functions and classes                                           ##\n",
        "############################################################################################################\n",
        "class NetworkWrapper(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, network, preprocess_fn):\n",
        "        super(NetworkWrapper, self).__init__()\n",
        "\n",
        "        self.preprocess_fn = preprocess_fn\n",
        "        self.network = network\n",
        "        self.network.eval()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.preprocess_fn(x)\n",
        "        x = self.network(x)\n",
        "        return x\n",
        "\n",
        "class Visualization(torch.nn.Module):\n",
        "    def __init__(self, h, w):\n",
        "        super(Visualization, self).__init__()\n",
        "        self.__data = torch.nn.Parameter(torch.randn(1, 3, h, w))\n",
        "\n",
        "    def __augment(self, x, batch_size, apply_all=True):\n",
        "\n",
        "        x = torch.cat([x] * batch_size, dim=0)\n",
        "\n",
        "        # Apply random augmentations to each image in the batch\n",
        "        if apply_all:\n",
        "            transform = torchvision.transforms.Compose([\n",
        "                torchvision.transforms.RandomResizedCrop([self.out_h, self.out_w]),\n",
        "                torchvision.transforms.RandomHorizontalFlip(),\n",
        "                torchvision.transforms.RandomRotation(360),\n",
        "                torchvision.transforms.RandomPerspective(),\n",
        "                torchvision.transforms.GaussianBlur(3),\n",
        "                torchvision.transforms.RandomGrayscale(p=0.1)\n",
        "            ])\n",
        "        else:\n",
        "            transform = torchvision.transforms.RandomResizedCrop([self.out_h, self.out_w])\n",
        "\n",
        "        augmented_images = torch.stack([transform(img) for img in x])\n",
        "\n",
        "        return augmented_images\n",
        "\n",
        "\n",
        "    def __reparameterize(self, x):\n",
        "\n",
        "        x = torch.nn.functional.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "    def set_output_shape(self, h, w):\n",
        "        self.out_h = h\n",
        "        self.out_w = w\n",
        "\n",
        "    def forward(self, batch_size, apply_all=True):\n",
        "        x = self.__data\n",
        "        x = self.__reparameterize(x)\n",
        "        x = self.__augment(x, batch_size, apply_all)\n",
        "        return x\n",
        "\n",
        "    def to_img(self):\n",
        "        with torch.no_grad():\n",
        "            x = self.__data\n",
        "            x = self.__reparameterize(x)\n",
        "\n",
        "        # fill here to create a PIL image from x\n",
        "        # and return it\n",
        "\n",
        "        x_np = x.detach().cpu().numpy().squeeze()\n",
        "\n",
        "        # Rescale values from (0, 1) to (0, 255) and change data type to uint8\n",
        "        x_np = (x_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Create a PIL image\n",
        "        pil_img = PIL.Image.fromarray(np.transpose(x_np, (1, 2, 0)))  # Reorder dimensions for PIL\n",
        "\n",
        "        return pil_img\n",
        "\n",
        "############################################################################################################\n",
        "##                         Initialize the model, visualization and optimizer                              ##\n",
        "############################################################################################################\n",
        "class_labels = [2, 76, 107, 340, 440, 479, 546, 836, 852, 947]\n",
        "\n",
        "for class_label in class_labels:\n",
        "\n",
        "    # RESNET with all augmentations\n",
        "    net = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "    resnet_preprocess_fn = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    resnet_model = NetworkWrapper(net, resnet_preprocess_fn).to(device)\n",
        "    resnet_vis = Visualization(256, 256).to(device)\n",
        "    resnet_vis.set_output_shape(224, 224)\n",
        "    resnet_optimizer = torch.optim.AdamW(params=resnet_vis.parameters(), lr=0.2)\n",
        "\n",
        "    # RESNET with one augmentation\n",
        "    net1_aug = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "    resnet1_aug_preprocess_fn = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    resnet1_aug_model = NetworkWrapper(net1_aug, resnet1_aug_preprocess_fn).to(device)\n",
        "    resnet1_aug_vis = Visualization(256, 256).to(device)\n",
        "    resnet1_aug_vis.set_output_shape(224, 224)\n",
        "    resnet1_aug_optimizer = torch.optim.AdamW(params=resnet1_aug_vis.parameters(), lr=0.2)\n",
        "\n",
        "    # VIT with all augmentations\n",
        "    net2 = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
        "\n",
        "    vit_preprocess_fn = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    vit_model = NetworkWrapper(net2, vit_preprocess_fn).to(device)\n",
        "    vit_vis = Visualization(256, 256).to(device)\n",
        "    vit_vis.set_output_shape(224, 224)\n",
        "    vit_optimizer = torch.optim.AdamW(params=vit_vis.parameters(), lr=0.2)\n",
        "\n",
        "    # VIT with one augmentation\n",
        "    net2_aug = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
        "\n",
        "    vit1_aug_preprocess_fn = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    vit1_aug_model = NetworkWrapper(net2_aug, vit1_aug_preprocess_fn).to(device)\n",
        "    vit1_aug_vis = Visualization(256, 256).to(device)\n",
        "    vit1_aug_vis.set_output_shape(224, 224)\n",
        "    vit1_aug_optimizer = torch.optim.AdamW(params=vit1_aug_vis.parameters(), lr=0.2)\n",
        "\n",
        "############################################################################################################\n",
        "##                                            Training loop                                               ##\n",
        "############################################################################################################\n",
        "\n",
        "    for i in range(1000):\n",
        "\n",
        "        # RESNET with all augmentations Training\n",
        "        resnet_vis.train()\n",
        "        resnet_optimizer.zero_grad()\n",
        "\n",
        "        output_resnet = resnet_model(resnet_vis(8))  # Using 8 as batch size\n",
        "        loss_resnet = -output_resnet[:, class_label].mean()  # Maximizing the score of the class\n",
        "\n",
        "        loss_resnet.backward()\n",
        "        resnet_optimizer.step()\n",
        "\n",
        "        # RESNET with one augmentation Training\n",
        "        resnet1_aug_vis.train()\n",
        "        resnet1_aug_optimizer.zero_grad()\n",
        "\n",
        "        output_resnet1_aug = resnet1_aug_model(resnet1_aug_vis(8, apply_all=False))  # Using 8 as batch size, apply only the first augmentation\n",
        "        loss_resnet1_aug = -output_resnet1_aug[:, class_label].mean()  # Maximizing the score of the class\n",
        "\n",
        "        loss_resnet1_aug.backward()\n",
        "        resnet1_aug_optimizer.step()\n",
        "\n",
        "        # VIT with all augmentations Training\n",
        "        vit_vis.train()\n",
        "        vit_optimizer.zero_grad()\n",
        "\n",
        "        output_vit = vit_model(vit_vis(8))  # Using 8 as batch size\n",
        "        loss_vit = -output_vit[:, class_label].mean()  # Maximizing the score of the class\n",
        "\n",
        "        loss_vit.backward()\n",
        "        vit_optimizer.step()\n",
        "\n",
        "        # VIT with one augmentation Training\n",
        "        vit1_aug_vis.train()\n",
        "        vit1_aug_optimizer.zero_grad()\n",
        "\n",
        "        output_vit1_aug = vit1_aug_model(vit1_aug_vis(8, apply_all=False))  # Using 8 as batch size, apply only the first augmentation\n",
        "        loss_vit1_aug = -output_vit1_aug[:, class_label].mean()  # Maximizing the score of the class\n",
        "\n",
        "        loss_vit1_aug.backward()\n",
        "        vit1_aug_optimizer.step()\n",
        "\n",
        "        # Show visualizations every 100 iterations\n",
        "        if (i + 1) % 100 == 0:\n",
        "            resnet_vis.eval()\n",
        "            resnet1_aug_vis.eval()\n",
        "            vit_vis.eval()\n",
        "            vit1_aug_vis.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                generated_img_resnet = resnet_vis.to_img()\n",
        "                generated_img_resnet_one = resnet1_aug_vis.to_img()\n",
        "                generated_img_vit = vit_vis.to_img()\n",
        "                generated_img_vit_one = vit1_aug_vis.to_img()\n",
        "\n",
        "                # Display visualizations for RESNET and VIT\n",
        "                plt.figure(figsize=(10, 3))\n",
        "\n",
        "                # RESNET with all Augmentations\n",
        "                plt.subplot(1, 4, 1)\n",
        "                plt.imshow(generated_img_resnet)\n",
        "                plt.title(\"ResNet with all Augmentations\", fontsize=7)\n",
        "                plt.axis('off')\n",
        "\n",
        "                # VIT with all Augmentations\n",
        "                plt.subplot(1, 4, 2)\n",
        "                plt.imshow(generated_img_resnet_one)\n",
        "                plt.title(\"ResNet with one Augmentation\", fontsize=7)\n",
        "                plt.axis('off')\n",
        "\n",
        "                # RESNET with one Augmentation\n",
        "                plt.subplot(1, 4, 3)\n",
        "                plt.imshow(generated_img_vit)\n",
        "                plt.title(\"VIT with all Augmentations\", fontsize=7)\n",
        "                plt.axis('off')\n",
        "\n",
        "                # VIT with one Augmentation\n",
        "                plt.subplot(1, 4, 4)\n",
        "                plt.imshow(generated_img_vit_one)\n",
        "                plt.title(\"VIT with one Augmentation\", fontsize=7)\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.suptitle(f\"Visualization {i+1} - Target class: {class_label}\", fontsize=10)\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "    image_name = f\"ResNet_all_augmentations_target_class_{class_label}.png\"\n",
        "    image_path = os.path.join(output_dir, image_name)\n",
        "    generated_img_resnet.save(image_path)\n",
        "\n",
        "    image_name = f\"ResNet_one_augmentation_target_class_{class_label}.png\"\n",
        "    image_path = os.path.join(output_dir, image_name)\n",
        "    generated_img_resnet_one.save(image_path)\n",
        "\n",
        "    image_name = f\"Vit_all_augmentations_target_class_{class_label}.png\"\n",
        "    image_path = os.path.join(output_dir, image_name)\n",
        "    generated_img_vit.save(image_path)\n",
        "\n",
        "    image_name = f\"Vit_one_augmentation_target_class_{class_label}.png\"\n",
        "    image_path = os.path.join(output_dir, image_name)\n",
        "    generated_img_vit_one.save(image_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
